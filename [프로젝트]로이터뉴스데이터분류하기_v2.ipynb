{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ecae0ed",
   "metadata": {},
   "source": [
    "### 1. 단어장 크기별 ML 성능비교표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133cceb7",
   "metadata": {},
   "source": [
    "![단어장 크기별 ML성능 비교표](./단어장크기별ML성능비교표.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ae7b3d0",
   "metadata": {},
   "source": [
    "### 2. ML과 딥러닝 성능비교표"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad72ba75",
   "metadata": {},
   "source": [
    "![ML과딥러닝 성능비교표](./ML과딥러닝성능비교표.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8939a390",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import reuters\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e05d1055",
   "metadata": {},
   "source": [
    "### 데이터준비\n",
    "- index -> text\n",
    "- DTM, TF-idf 학습 데이터 준비\n",
    "- Word2Vector 학습 데이터 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae27cd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이부분에있는 num_words를 5000과 다른방법으로 바꿔보세요~\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = reuters.load_data(num_words=None, test_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3964f25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 원본 뉴스 데이터로 복원해보기\n",
    "word_index = reuters.get_word_index(path=\"reuters_word_index.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a90768a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 정수로부터 단어를 얻을 수 있는 index_word\n",
    "index_to_word = { index+3 : word for word, index in word_index.items() }\n",
    "\n",
    "# index_to_word에 숫자 0은 <pad>, 숫자 1은 <sos>, 숫자 2는 <unk>를 넣어줍니다.\n",
    "for index, token in enumerate((\"<pad>\", \"<sos>\", \"<unk>\")):\n",
    "    index_to_word[index]=token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37d0edd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8982\n",
      "2246\n"
     ]
    }
   ],
   "source": [
    "# 전체 훈련용 뉴스 데이터와 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환해 보겠습니다.\n",
    "\n",
    "# 전체 훈련용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_train)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_train[i]])\n",
    "    decoded.append(t)\n",
    "    \n",
    "x_train = decoded\n",
    "print(len(x_train))\n",
    "\n",
    "# 전체 테스트용 뉴스 데이터를 텍스트 데이터로 변환\n",
    "decoded = []\n",
    "for i in range(len(x_test)):\n",
    "    t = ' '.join([index_to_word[index] for index in x_test[i]])\n",
    "    decoded.append(t)\n",
    "    \n",
    "x_test = decoded\n",
    "print(len(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "162b445d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 벡터화 DTM, TF-idf 방법\n",
    "dtmvector = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "x_train_dtm = dtmvector.fit_transform(x_train)\n",
    "x_test_dtm= dtmvector.transform(x_test)\n",
    "\n",
    "x_train_tfidf = tfidf_transformer.fit_transform(x_train_dtm)\n",
    "x_test_tfidf = tfidf_transformer.transform(x_test_dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec244640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "모델 학습 완료!\n"
     ]
    }
   ],
   "source": [
    "# 벡터화 W2V방법\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# 우선 문장을 토큰화 시킵시다 띄어쓰기 기반으로 해볼게요! -> # 위에서 DTM만들때는 왜 안해줬냐! -> CountVectorizer에서 띄어쓰기 기반 토큰화가 내장되있음\n",
    "x_train_tokenized = [sentence.split() for sentence in x_train]\n",
    "x_test_tokenized = [sentence.split() for sentence in x_test]\n",
    "\n",
    "# vector사이즈를 늘리거나 줄여보세요 아마 512 가장많이쓰이는 방식\n",
    "model = Word2Vec(sentences = x_train_tokenized, vector_size = 256, window = 5, min_count = 5, workers = 4, sg = 0)\n",
    "print(\"모델 학습 완료!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b95906f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('harbour', 0.8768444657325745), ('halmi', 0.876131534576416), ('jim', 0.8596214056015015), ('monopoly', 0.8559353351593018), ('shelf', 0.8543671369552612), ('okla', 0.8474838137626648), ('puerto', 0.8456472754478455), ('alcan', 0.845412015914917), ('missouri', 0.8443841934204102), ('alabama', 0.8442700505256653)]\n"
     ]
    }
   ],
   "source": [
    "# W2V이 잘되었는지 확인\n",
    "model_result = model.wv.most_similar('man')\n",
    "print(model_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ac93da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습된 Word2Vec 모델\n",
    "w2v_model = model\n",
    "\n",
    "# 각 문장을 벡터화 시키는 코드\n",
    "def vectorize_sentence(sentence, model, max_len):\n",
    "    vecs = []\n",
    "    for word in sentence:\n",
    "        if word in model.wv:\n",
    "            vecs.append(model.wv[word])\n",
    "        else:\n",
    "            vecs.append(np.zeros(model.vector_size))\n",
    "    # Padding\n",
    "    if len(vecs) < max_len:\n",
    "        vecs += [np.zeros(model.vector_size)] * (max_len - len(vecs))\n",
    "    else:\n",
    "        vecs = vecs[:max_len]\n",
    "    return np.array(vecs)\n",
    "\n",
    "\n",
    "# 최대 문장길이를 잘 잡아주세요\n",
    "x_train_w2v = np.array([vectorize_sentence(s, w2v_model, max_len=100) for s in x_train_tokenized])\n",
    "x_test_w2v = np.array([vectorize_sentence(s, w2v_model, max_len=100) for s in x_test_tokenized])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea117467",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8982, 100, 256)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_w2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d19d82c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2246, 100, 256)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_w2v.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e8cdc1",
   "metadata": {},
   "source": [
    "### 모델 정의 및 실험"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bda653e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 결정트리 분류모델 학습\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "dt_clf.fit(x_train_tfidf, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7f4ad8b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy : 0.6211\n",
      "✅ F1-score : 0.5769\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "y_pred = dt_clf.predict(x_test_tfidf)\n",
    "\n",
    "# 평가지표\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"✅ Accuracy : {acc:.4f}\")\n",
    "print(f\"✅ F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44057776",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8982, 256)\n"
     ]
    }
   ],
   "source": [
    "# 데이터를 단어단위에서 문장단위로 바꿔줘야합니다.. ML은 2차원데이터만 받을수있기때문\n",
    "# 문장에 대해서 토큰들의 벡터를 평균을 취해줍니다.\n",
    "\n",
    "# Word2Vec 임베딩 시퀀스: (8982, 100, 256)\n",
    "x_w2v_seq_train = x_train_w2v\n",
    "x_w2v_seq_test = x_test_w2v\n",
    "# 평균 풀링 → (8982, 256)\n",
    "x_w2v_avg_train = np.mean(x_w2v_seq_train, axis=1)\n",
    "x_w2v_avg_test = np.mean(x_w2v_seq_test, axis=1)\n",
    "\n",
    "print(x_w2v_avg_train.shape)  # (8982, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f68fd095",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(max_depth=10, random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Word2Vec 데이터로 결정트리 분류 모델 학습하기\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_clf = DecisionTreeClassifier(max_depth=10, random_state=0)\n",
    "dt_clf.fit(x_w2v_avg_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fc7f3f42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy : 0.6443\n",
      "✅ F1-score : 0.6374\n"
     ]
    }
   ],
   "source": [
    "# 예측\n",
    "y_pred = dt_clf.predict(x_w2v_avg_test)\n",
    "\n",
    "# 평가 지표\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"✅ Accuracy : {acc:.4f}\")\n",
    "print(f\"✅ F1-score : {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d7bea0",
   "metadata": {},
   "source": [
    "### Dense NN 딥러닝 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b148a82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 25600)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               13107712  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 46)                5934      \n",
      "=================================================================\n",
      "Total params: 13,179,310\n",
      "Trainable params: 13,179,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout, LSTM, Dense, Dropout\n",
    "\n",
    "\n",
    "dense_model = Sequential([\n",
    "    Flatten(input_shape=(100, 256)),  # (seq_len, embedding_dim)\n",
    "    Dense(512, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(46, activation='softmax')   # 클래스 수에 맞게 조정 46개로 맞춰주세요!\n",
    "])\n",
    "\n",
    "dense_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "dense_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "194973c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 3s 8ms/step - loss: 1.8857 - accuracy: 0.5819 - val_loss: 1.4623 - val_accuracy: 0.6728\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.3457 - accuracy: 0.6788 - val_loss: 1.3719 - val_accuracy: 0.6945\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 1.0807 - accuracy: 0.7383 - val_loss: 1.3859 - val_accuracy: 0.6789\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.9137 - accuracy: 0.7822 - val_loss: 1.4035 - val_accuracy: 0.6856\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.7423 - accuracy: 0.8129 - val_loss: 1.4242 - val_accuracy: 0.6861\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.6658 - accuracy: 0.8373 - val_loss: 1.4500 - val_accuracy: 0.6967\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.5796 - accuracy: 0.8575 - val_loss: 1.5799 - val_accuracy: 0.6811\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.5375 - accuracy: 0.8692 - val_loss: 1.6914 - val_accuracy: 0.6962\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.4761 - accuracy: 0.8807 - val_loss: 1.6400 - val_accuracy: 0.6845\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 1s 6ms/step - loss: 0.4944 - accuracy: 0.8835 - val_loss: 1.7583 - val_accuracy: 0.6694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7699aa9ce160>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시간이 좀 걸립니다! 한 20분정도..\n",
    "\n",
    "# Word2Vec 벡터화된 학습 데이터\n",
    "dense_model.fit(x_train_w2v, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ee3b25fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy: 0.6906\n",
      "✅ F1-score: 0.6730\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = dense_model.predict(x_test_w2v)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "print(f\"✅ F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3dfc49",
   "metadata": {},
   "source": [
    "### RNN 딥러닝 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a3074f63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 128)               197120    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 46)                2990      \n",
      "=================================================================\n",
      "Total params: 208,366\n",
      "Trainable params: 208,366\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# rnn 시계열 특징 데이터 특화 모델\n",
    "\n",
    "rnn_model = Sequential([\n",
    "    LSTM(128, input_shape=(100, 256)),  # (seq_len, embedding_dim)\n",
    "    Dropout(0.3),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.3),\n",
    "    Dense(46, activation='softmax')   # 클래스 수에 맞게 조정 46개로 맞춰주세요~\n",
    "])\n",
    "\n",
    "rnn_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "rnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "907f0af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "225/225 [==============================] - 5s 12ms/step - loss: 2.1990 - accuracy: 0.4589 - val_loss: 1.7804 - val_accuracy: 0.5615\n",
      "Epoch 2/10\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.6835 - accuracy: 0.5904 - val_loss: 1.5447 - val_accuracy: 0.6216\n",
      "Epoch 3/10\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.5066 - accuracy: 0.6316 - val_loss: 1.3851 - val_accuracy: 0.6578\n",
      "Epoch 4/10\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.4239 - accuracy: 0.6519 - val_loss: 1.2859 - val_accuracy: 0.6850\n",
      "Epoch 5/10\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.2814 - accuracy: 0.6877 - val_loss: 1.1840 - val_accuracy: 0.7168\n",
      "Epoch 6/10\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.2053 - accuracy: 0.7061 - val_loss: 1.1600 - val_accuracy: 0.7223\n",
      "Epoch 7/10\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.1656 - accuracy: 0.7116 - val_loss: 1.1606 - val_accuracy: 0.7268\n",
      "Epoch 8/10\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.1045 - accuracy: 0.7265 - val_loss: 1.0953 - val_accuracy: 0.7368\n",
      "Epoch 9/10\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.0560 - accuracy: 0.7363 - val_loss: 1.1061 - val_accuracy: 0.7407\n",
      "Epoch 10/10\n",
      "225/225 [==============================] - 2s 8ms/step - loss: 1.0245 - accuracy: 0.7425 - val_loss: 1.1274 - val_accuracy: 0.7346\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7699a95e63a0>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 시간이 좀 걸립니다! 한 20분정도\n",
    "rnn_model.fit(x_train_w2v, y_train, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9687296b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Accuracy: 0.7182\n",
      "✅ F1-score: 0.6853\n"
     ]
    }
   ],
   "source": [
    "y_pred_proba = rnn_model.predict(x_test_w2v)\n",
    "y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "acc = accuracy_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "print(f\"✅ Accuracy: {acc:.4f}\")\n",
    "print(f\"✅ F1-score: {f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134b59e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
